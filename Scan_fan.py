    # ********************___02_selenium_00__draft___************************
'''
–ó–∞—Ö–æ–¥–∏—Ç –Ω–∞ —Å–∞–π—Ç —Ç—Ä–µ–Ω–µ—Ä–æ–≤–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞, –ø–∞—Ä—Å–∏—Ç —Ü–∏—Ç–∞—Ç—ã —Å 10 —Å—Ç—Ä–∞–Ω–∏—Ü
Legend:
üü¢  1)  –°–æ–∑–¥–∞—Ç—å –ø—Ä–æ–µ–∫—Ç
üü°  2)  –ù–∞–π—Ç–∏ –Ω–∞ —Å–∞–π—Ç–µ —Å—Å—ã–ª–∫—É –∏ —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª
üî¥  3)  –°–¥–µ–ª–∞—Ç—å –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ–µ

'''
# import requests
# from fake_useragent import UserAgent

from bs4 import BeautifulSoup
from selenium.webdriver import Firefox
import pandas as pd

webdriver = "/home/danya/.local/bin/"

driver = Firefox(webdriver)

# url = 'https://quotes.toscrape.com/'
# url = 'https://2ip.ru/'
# url = 'https://www1.thepiratebay3.to/top/all'

pages = 10
for page in range(1, pages):
    url = "http://quotes.toscrape.com/js/page/" + str(page) + "/"
    driver.get(url)
    items = len(driver.find_elements_by_class_name("quote"))
    total = []
    for item in range(items):
        quotes = driver.find_elements_by_class_name("quote")
        for quote in quotes:
            quote_text = quote.find_element_by_class_name('text').text
            author = quote.find_element_by_class_name('author').text
            new = ((quote_text, author))
            total.append(new)
    df = pd.DataFrame(total, columns=['quote', 'author'])
    df.to_csv('quoted.csv')
driver.close()




'''
response = driver.get(url)
# response = requests.get(url, headers={'User-Agent': UserAgent().chrome})
# response = requests.get(url)
soup = BeautifulSoup(response.text, 'lxml')

# print(soup)
file=open(("test.html"),"w")
file.write(str(soup))
file.close()
'''